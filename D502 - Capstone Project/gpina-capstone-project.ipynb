{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: matplotlib in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (3.7.3)\n",
      "Requirement already satisfied: seaborn in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (0.13.2)\n",
      "Requirement already satisfied: statsmodels in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (0.14.1)\n",
      "Requirement already satisfied: requests in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (2.32.3)\n",
      "Requirement already satisfied: openpyxl in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (3.1.5)\n",
      "Requirement already satisfied: yfinance in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (0.2.54)\n",
      "Requirement already satisfied: kaggle in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (1.6.17)\n",
      "Requirement already satisfied: python-dotenv in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: et-xmlfile in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: six>=1.10 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: bleach in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: webencodings in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/pinagm/anaconda3/envs/udacity/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib seaborn statsmodels requests openpyxl yfinance kaggle python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install /home/pinagm/beaapi-0.0.2-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ETF Fund data from State Street Global Advisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import  yfinance as yf\n",
    "from typing import List\n",
    "import beaapi as bea\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "# Output the filtered DataFrame\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_process_etf_data(etf_list):\n",
    "    ssga = [etf.lower() for etf in etf_list]\n",
    "    subfolder = 'SSGA Data'\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "\n",
    "    ssga_df_list = []\n",
    "\n",
    "    for etf in ssga:\n",
    "        url = f'https://www.ssga.com/library-content/products/fund-data/etfs/us/holdings-daily-us-en-{etf}.xlsx'\n",
    "        response = req.get(url)\n",
    "        current_date = datetime.now().strftime('%m-%d-%Y')\n",
    "        file_path = os.path.join(subfolder, f'{etf}-{current_date}.xlsx')\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        df = pd.read_excel(file_path, skiprows=4, header=0, usecols=\"A:H\")\n",
    "        \n",
    "        drop_index = df[df['Name'] == \"Past performance is not a reliable indicator of future performance. Investment return and principal value will fluctuate, so you may have a gain or loss when shares are sold. Current performance may be higher or lower than that quoted. All results are historical and assume the reinvestment of dividends and capital gains. Visit www.ssga.com for most recent month-end performance. \"].index\n",
    "\n",
    "        if not drop_index.empty:\n",
    "            df = df[:drop_index[0]]\n",
    "\n",
    "        if df.iloc[-1].isna().all():\n",
    "            df = df[:-1]\n",
    "\n",
    "        ssga_df_list.append(df)\n",
    "\n",
    "    return ssga_df_list\n",
    "\n",
    "# Testing Output\n",
    "etf_list = ['XLI', 'XLK', 'XLE', 'XLB']\n",
    "ssga_df_list = fetch_and_process_etf_data(etf_list)\n",
    "for df in ssga_df_list:\n",
    "    print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bea_data(api_key, years):\n",
    "    # base_url = \"https://apps.bea.gov/api/data/\"\n",
    "    # params = {\n",
    "    #     \"UserID\": api_key,\n",
    "    #     \"method\": \"GetData\",\n",
    "    #     \"datasetname\": \"GDPbyIndustry\",\n",
    "    #     \"Frequency\": \"A,Q\",\n",
    "    #     \"Year\": years,\n",
    "    #     \"Industry\": \"ALL\",\n",
    "    #     \"TableID\": \"ALL\",\n",
    "    #     \"ResultFormat\": \"JSON\"\n",
    "    # }\n",
    "    try:\n",
    "        # response = req.get(base_\n",
    "        # \n",
    "        # \n",
    "        # url, params=params)\n",
    "        # response.raise_for_status()\n",
    "        tbl = bea.get_data(api_key, datasetname=\"GDPbyIndustry\", Frequency=\"A,Q\", Year=\"2020,2021,2022,2023,2024\", TableID=\"ALL\", Industry=\"ALL\")\n",
    "        bea_df_new = pd.DataFrame(bea.to_wide_vars_in_rows(tbl))\n",
    "        data = bea_df_new\n",
    "        # if 'Error' in data['BEAAPI']:\n",
    "        #     error_code = data['BEAAPI']['Error']['APIErrorCode']\n",
    "        #     error_description = data['BEAAPI']['Er4ror']['APIErrorDescription']\n",
    "        #     print(f\"API request failed with error4 code {error_code}: {error_description}\")\n",
    "        #     return None\n",
    "        print(data)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"API request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_bea_data(data):\n",
    "    # if 'BEAAPI' not in data or 'Results' not in data['BEAAPI']:\n",
    "    #     print(\"Error: 'Results' key not found in the API response.\")\n",
    "    #     return None\n",
    "    # results = data['BEAAPI']['Results']\n",
    "    \n",
    "    bea_df = pd.DataFrame(data)\n",
    "    bea_df.rename(columns={\"IndustrYDescription\": \"IndustryDescription\"}, inplace=True)\n",
    "    grouped_df = bea_df.groupby(['Industry', 'IndustryDescription'], as_index=False)['DataValue'].sum()\n",
    "    filtered_df = grouped_df[~grouped_df['IndustryDescription'].isin([\n",
    "        \"Taxes on production and imports less subsidies\",\n",
    "        \"Compensation of employees\",\n",
    "        \"Gross operating surplus\"\n",
    "    ])]\n",
    "    return filtered_df\n",
    "\n",
    "def save_bea_data(filtered_df):\n",
    "    subfolder = 'BEA Data'\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "    current_date = datetime.now().strftime('%m-%d-%Y')\n",
    "    file_path = os.path.join(subfolder, f\"bea-gdp-by-industry-raw-{current_date}.xlsx\")\n",
    "    filtered_df.to_excel(file_path, index=False)\n",
    "    return file_path\n",
    "\n",
    "def map_sectors(filtered_df):\n",
    "    sector_map = {\n",
    "        \"Technology\": [\n",
    "            \"Computer and electronic products\",\n",
    "            \"Computer systems design and related services\",\n",
    "            \"Data processing, internet publishing, and other information services\",\n",
    "            \"Information-communications-technology-producing industries\"\n",
    "        ],\n",
    "        \"Materials\": [\n",
    "            \"Agriculture, forestry, fishing, and hunting\",\n",
    "            \"Farms\",\n",
    "            \"Forestry, fishing, and related activities\",\n",
    "            \"Mining\",\n",
    "            \"Mining, except oil and gas\",\n",
    "            \"Support activities for mining\",\n",
    "            \"Wood products\",\n",
    "            \"Paper products\",\n",
    "            \"Chemical products\",\n",
    "            \"Plastics and rubber products\",\n",
    "            \"Nonmetallic mineral products\",\n",
    "            \"Primary metals\",\n",
    "            \"Fabricated metal products\"\n",
    "        ],\n",
    "        \"Energy\": [\n",
    "            \"Oil and gas extraction\",\n",
    "            \"Petroleum and coal products\",\n",
    "            \"Pipeline transportation\"\n",
    "        ],\n",
    "        \"Industrials\": [\n",
    "            \"Construction\",\n",
    "            \"Machinery\",\n",
    "            \"Electrical equipment, appliances, and components\",\n",
    "            \"Other transportation equipment\",\n",
    "            \"Miscellaneous manufacturing\",\n",
    "            \"Durable goods\",\n",
    "            \"Wholesale trade\",\n",
    "            \"Rail transportation\",\n",
    "            \"Water transportation\",\n",
    "            \"Truck transportation\",\n",
    "            \"Transit and ground passenger transportation\",\n",
    "            \"Other transportation and support activities\",\n",
    "            \"Transportation and warehousing\",\n",
    "            \"Warehousing and storage\",\n",
    "            \"Waste management and remediation services\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    def get_sector(category):\n",
    "        for sector, cat_list in sector_map.items():\n",
    "            if category in cat_list:\n",
    "                return sector\n",
    "        return \"Other\"\n",
    "\n",
    "    filtered_df = filtered_df.copy()\n",
    "    filtered_df.loc[:, \"Sector\"] = filtered_df[\"IndustryDescription\"].apply(get_sector)\n",
    "    focus_sectors = [\"Technology\", \"Materials\", \"Energy\", \"Industrials\"]\n",
    "    df_filtered = filtered_df[filtered_df[\"Sector\"].isin(focus_sectors)]\n",
    "    return df_filtered\n",
    "\n",
    "def fetch_bea_gdp_by_industry(api_key, years):\n",
    "    data = fetch_bea_data(api_key, years)\n",
    "    if data is None:\n",
    "        return None\n",
    "    filtered_df = process_bea_data(data)\n",
    "    if filtered_df is not None:\n",
    "        save_bea_data(filtered_df)\n",
    "        df_filtered = map_sectors(filtered_df)\n",
    "        current_date = datetime.now().strftime('%m-%d-%Y')\n",
    "        subfolder = 'BEA Data'\n",
    "        filtered_file_path = os.path.join(subfolder, f\"bea-gdp-by-industry-filtered-{current_date}.xlsx\")\n",
    "        df_filtered.to_excel(filtered_file_path, index=False)\n",
    "        return df_filtered\n",
    "    else:\n",
    "        print(\"Error: Processed data is None.\")\n",
    "        return None\n",
    "\n",
    "# Output the filtered DataFrame\n",
    "api_key = os.environ.get(\"beakey\")\n",
    "years = \"2020,2021,2022,2023, 2024\"\n",
    "bea_df = fetch_bea_gdp_by_industry(api_key, years)\n",
    "if bea_df is not None:\n",
    "    print(bea_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_kaggle_data():\n",
    "    # Step 1: Ensure the \"Kaggle Data\" directory exists\n",
    "    kaggle_data_dir = \"Kaggle Data\"\n",
    "    os.makedirs(kaggle_data_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 2: Check if the .csv file already exists\n",
    "    csv_exists = any(filename.endswith('.csv') for filename in os.listdir(kaggle_data_dir))\n",
    "    \n",
    "    if not csv_exists:\n",
    "        # Step 3: Download the dataset using the Kaggle CLI\n",
    "        dataset = \"jakewright/9000-tickers-of-stock-market-data-full-history\"\n",
    "        subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset], check=True)\n",
    "        \n",
    "        # Step 4: Unzip the downloaded file\n",
    "        zip_filename = dataset.split('/')[-1] + \".zip\"\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(kaggle_data_dir)\n",
    "        \n",
    "        # Step 5: Remove any files in the \"Kaggle Data\" directory that are not .csv files\n",
    "        for filename in os.listdir(kaggle_data_dir):\n",
    "            if not filename.endswith('.csv'):\n",
    "                os.remove(os.path.join(kaggle_data_dir, filename))\n",
    "        \n",
    "        # Optionally, remove the downloaded zip file\n",
    "        os.remove(zip_filename)\n",
    "\n",
    "# Call the function\n",
    "setup_kaggle_data()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "kag_df = pd.read_csv('Kaggle Data/all_stock_data.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "kag_df['Date'] = pd.to_datetime(kag_df['Date'])\n",
    "\n",
    "# Filter the DataFrame for dates between 2020-01-01 and 2023-12-31\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-12-31'\n",
    "filtered_kag_df = kag_df[(kag_df['Date'] >= start_date) & (kag_df['Date'] <= end_date)]\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "filtered_kag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_kag_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(directory: str) -> None:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "def download_data(tickers: List[str], start_date: str, end_date: str, interval: str) -> pd.DataFrame:\n",
    "    return yf.download(\n",
    "        tickers=tickers,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        interval=interval,\n",
    "        group_by=\"ticker\",\n",
    "        auto_adjust=True,\n",
    "        threads=True,\n",
    "        progress=True\n",
    "    )\n",
    "\n",
    "def filter_columns(df: pd.DataFrame, tickers: List[str], fields: List[str]) -> pd.DataFrame:\n",
    "    keep_cols = [(t, field) for t in tickers for field in fields if (t, field) in df.columns]\n",
    "    return df[keep_cols].copy()\n",
    "\n",
    "def add_change_columns(df: pd.DataFrame, tickers: List[str]) -> pd.DataFrame:\n",
    "    for t in tickers:\n",
    "        if (t, \"High\") in df.columns and (t, \"Low\") in df.columns:\n",
    "            df[(t, \"Change\")] = df[(t, \"High\")] - df[(t, \"Low\")]\n",
    "    return df\n",
    "\n",
    "def process_change_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_only_change = df.loc[:, (slice(None), \"Change\")].copy()\n",
    "    df_only_change.columns = df_only_change.columns.droplevel(1)\n",
    "    df_only_change.columns = [f\"{ticker}_Change\" for ticker in df_only_change.columns]\n",
    "    df_only_change.reset_index(inplace=True)\n",
    "    if df_only_change.columns[0] == \"index\":\n",
    "        df_only_change.rename(columns={\"index\": \"Date\"}, inplace=True)\n",
    "    return df_only_change\n",
    "\n",
    "def save_to_csv(df: pd.DataFrame, path: str) -> None:\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Data with only 'Change' columns saved to: {path}\")\n",
    "\n",
    "# Main execution flow\n",
    "data_dir = \"Yahoo Data\"\n",
    "ensure_directory_exists(data_dir)\n",
    "\n",
    "tickers = [\"XLI\", \"XLK\", \"XLE\", \"XLB\"]\n",
    "df_full = download_data(tickers, \"2020-01-01\", \"2024-01-01\", \"3mo\")\n",
    "\n",
    "df_filtered = filter_columns(df_full, tickers, [\"High\", \"Low\"])\n",
    "df_filtered = add_change_columns(df_filtered)\n",
    "\n",
    "df_only_change = process_change_columns(df_filtered)\n",
    "\n",
    "csv_path = os.path.join(data_dir, \"sector_quarterly_only_change.csv\")\n",
    "save_to_csv(df_only_change, csv_path)\n",
    "\n",
    "print(df_only_change.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
